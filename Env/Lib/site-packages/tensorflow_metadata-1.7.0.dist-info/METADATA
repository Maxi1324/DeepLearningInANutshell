Metadata-Version: 2.1
Name: tensorflow-metadata
Version: 1.7.0
Summary: Library and standards for schema and statistics.
Download-URL: https://github.com/tensorflow/metadata/tags
Author: Google Inc.
Author-email: tensorflow-extended-dev@googlegroups.com
License: Apache 2.0
Keywords: tensorflow metadata tfx
Platform: UNKNOWN
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Software Development
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.7,<4
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: absl-py (<2.0.0,>=0.9)
Requires-Dist: googleapis-common-protos (<2,>=1.52.0)
Requires-Dist: protobuf (<4,>=3.13)

# TensorFlow Metadata

[![Python](https://img.shields.io/pypi/pyversions/tensorflow-metadata.svg?style=plastic)](https://github.com/tensorflow/metadata)
[![PyPI](https://badge.fury.io/py/tensorflow-metadata.svg)](https://badge.fury.io/py/tensorflow-metadata)

TensorFlow Metadata provides standard representations for metadata that are
useful when training machine learning models with TensorFlow.

The metadata serialization formats include:

* A schema describing tabular data (e.g., tf.Examples).
* A collection of summary statistics over such datasets.
* A problem statement quantifying the objectives of a model.

The metadata may be produced by hand or automatically during input data
analysis, and may be consumed for data validation, exploration, and
transformation.


